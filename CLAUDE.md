# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Build System

This is a Dune-based OCaml monorepo. Common commands:

- `dune build` - Build all libraries and executables
- `dune runtest` - Run inline tests (using ppx_inline_test)
- `dune build @fmt` - Check code formatting
- `dune promote` - Promote test outputs
- `make dev` - Setup development environment (locks dependencies, builds, installs ocamllsp and ocamlformat)

All libraries use `(flags (:standard -warn-error -A))` which turns off treating warnings as errors.

## Library Architecture

### staged

A staged metaprogramming language with compile-time and runtime stages. Key modules:

- `Staged_syntax` - AST definition with `Stage.t` (Runtime | Comptime), expression types (functions, applications, let bindings), and type system (Ty_fun with stage annotations)
- `Staged_infer` - Type inference with bidirectional typing, tracks variable types in environment
- `Staged_evaluate` - Multi-stage evaluator that handles both compile-time and runtime evaluation, uses fuel-based recursion limits
- `Staged_var` - Variable representation with unique IDs
- `Staged_parse` - Parser for the staged language
- `Staged_tests` - Test suite with helper functions for constructing expressions

Dependencies: `shrubbery`, `utility`, `core`

### shrubbery

A layout-sensitive parsing library using indentation and grouping. Modules:

- `Shrubbery_lexer` - Tokenization
- `Shrubbery_token` / `Shrubbery_token_tree` - Token representation
- `Shrubbery_parser` - Stateful parser that builds syntax trees
- `Shrubbery_syntax` - Syntax tree with groups, blocks, items, and alternatives
- `Shrubbery_delimit` / `Shrubbery_layout` - Layout handling

Dependencies: `core`

### functional

Functional programming abstractions:

- `Functional_fold` - Folding operations with builder pattern (uses `@>` operator)
- `Functional_iter` - Iteration abstractions
- `Functional_traverse` - Traversal operations (uses `&` operator)
- `Functional.Syntax` - Syntax helpers with `let@` and `let@:` operators for monadic/applicative style

Dependencies: `core`

### parsec

Parser combinator library with streaming interface:

- `Parsec_intf` - Core interfaces for Token, Stream, Chunk
- `Make_stream` - Generic stream implementation over token arrays
- `String_stream` - Specialized stream for character parsing

Dependencies: `core`

### utility

Utility modules:

- `Utility_acc` - Efficient accumulator type that avoids quadratic list append operations. Uses tree structure (Empty, Singleton, Cons, List, Append, Concat) with optimized `to_list` conversion

Dependencies: `core`

### sexp_lang

S-expression language implementation (structure unclear from inspection).

### ai libraries

Libraries generated by ai live in the ai/ folder.

## Code Style Conventions

### Module-per-Type Pattern

Follow the OCaml convention of using separate modules for each major type, with the type named `t`:

```ocaml
module Value : sig
  type t =
    | String of string
    | Integer of int64
    | ...
  [@@deriving sexp, compare, equal]

  val string : string -> t
  val integer : int64 -> t
  ...
end

module Date : sig
  type t = {
    year : int;
    month : int;
    day : int;
  }
  [@@deriving sexp, compare, equal]
end
```

Benefits:

- Clear namespacing (e.g., `Value.t`, `Date.t`)
- Consistent with Core and other OCaml libraries
- Related functions are grouped with their types
- Better encapsulation and abstraction

### Exception-Based Internal Implementation with Result Interface

For parsers, lexers, and other complex control flow, use exceptions internally for cleaner code and better performance, then provide a public API that returns `result` types:

```ocaml
module Parse_error = struct
  type t = {
    message : string;
    location : string option;
  }
  [@@deriving sexp]
end

exception Parse_error of Parse_error.t

(* Internal implementation uses exceptions *)
let parse_internal input =
  if invalid input then
    raise_notrace (Parse_error { message = "Invalid input"; location = None })
  else
    (* ... parse logic ... *)
    result

(* Public API converts exceptions to results *)
let parse input =
  try Ok (parse_internal input) with
  | Parse_error err -> Error err

(* Or using Or_error for simpler cases *)
let parse input =
  Or_error.try_with (fun () -> parse_internal input)
```

Benefits:

- Cleaner internal code without threading `result` through every function
- Better performance (exceptions for control flow in OCaml are efficient)
- Maintains a safe, explicit error-handling API for library users
- Easier to refactor and maintain complex parsers

**Important**: Use `raise_notrace` instead of `raise` when using exceptions for control flow. This avoids the performance overhead of capturing backtraces for expected error conditions.

### Commit Pattern in Parsers

When a parser has matched enough of a construct to be certain about what it's parsing (e.g., a keyword prefix), it should "commit" and stop producing backtrackable `Fail` exceptions. Instead, subsequent errors should be hard errors reported to the user.

The commit pattern works by forgetting the failure handle `h`:

```ocaml
and parse_fun_ty st h items : Syntax.expr =
  let item = Items.next h items in
  let fun_tok, purity =
    Fail.one_of
      [ (fun () -> Match.builtin h "Fun" item, Syntax.Purity.Pure)
      ; (fun () -> Match.builtin h "Funct" item, Syntax.Purity.Impure)
      ]
  in
  (* Commit: no more Failures after matching Fun/Funct *)
  let h = () in
  ignore h;
  (* From here on, use run_or_thunk to convert Fail to hard errors *)
  let params_item =
    Fail.run_or_thunk
      ~f:(fun h -> Items.next h items |> Match.Item.tree h)
      ~default:(fun () -> error (Error.create "Expected parameter list" fun_tok.index))
  in
  ...
```

Key points:

- After matching the distinguishing prefix (e.g., `Fun` or `Funct`), set `let h = () in ignore h`
- This shadows the failure handle, preventing accidental use
- Use `Fail.run_or_thunk` with `~default` to explicitly throw hard errors on failure
- The `~f` parameter gets a fresh handle for operations that need one

### Prefer Pattern Matching Over Equality Functions

When matching on record fields or variant payloads, use pattern matching instead of equality functions like `Token.equal`:

```ocaml
(* Good: Pattern matching *)
match State.peek st with
| Some (Token { token = VLBrace; _ }) -> ...
| Some (Token { token = Colon | Equal; _ }) -> ...
| Some (Delim { ldelim = { token = LBrace; _ }; tts; rdelim }) -> ...

(* Less preferred: Equality functions with guards *)
match State.peek st with
| Some (Token ti) when Token.equal ti.token VLBrace -> ...
| Some (Token ti) when Token.equal ti.token Colon || Token.equal ti.token Equal -> ...
```

Benefits:

- More idiomatic OCaml
- Compiler can check exhaustiveness
- Often more concise, especially with or-patterns
- Binds values directly without needing to extract from records

### Use Or-Patterns for Common Field Extraction

When multiple variants share a common field and the same operation is performed on all of them, use or-patterns to consolidate the cases:

```ocaml
(* Good: Or-pattern for common field extraction *)
let expr_span (e : expr) : Span.t =
  match e with
  | Expr_var { span; _ }
  | Expr_seal { span; _ }
  | Expr_app { span; _ }
  | Expr_abs { span; _ }
  | Expr_ty_fun { span; _ }
  | Expr_proj { span; _ }
  | Expr_mod { span; _ }
  | Expr_let { span; _ }
  | Expr_bool { span; _ }
  | Expr_unit { span }
  | Expr_int { span; _ }
  | Expr_hole { span; _ }
  | Expr_if { span; _ } ->
    span

(* Less preferred: Repetitive individual cases *)
let expr_span (e : expr) : Span.t =
  match e with
  | Expr_var { span; _ } -> span
  | Expr_seal { span; _ } -> span
  | Expr_app { span; _ } -> span
  | Expr_abs { span; _ } -> span
  (* ... many more repetitive lines ... *)
```

Benefits:

- More concise and easier to read
- Single point of change for the common operation
- Compiler ensures all variants in the or-pattern bind the same names
- Makes it obvious that all cases are handled uniformly

## Naming conventions

Follow core library naming conventions:

- **Modules**: Upper_snake_case (e.g., `String_stream`, `Toml_parser`)
- **Constructors/Variants**: Upper_snake_case (e.g., `Some`, `None`, `Ok`, `Error`, `Left_bracket`, `Parse_error`)
- **Functions/Values**: lower_snake_case (e.g., `parse_value`, `to_string`, `check_input`)
- **File naming**: For a library named `lib` and modules `mod1` and `mod2`, name the files `lib_mod1.ml` and `lib_mod2.ml`

Example:

```ocaml
module Token = struct
  type t =
    | String of string
    | Integer of int64
    | Left_bracket
    | Veof
  [@@deriving sexp, compare, equal]
end

let parse_token input = ...
```

## Testing Conventions

### Prefer Expect Tests with Check Functions in Test Modules

Organize tests in test modules and use check-style helper functions to reduce boilerplate:

```ocaml
(* Good: Test module with check functions *)
let%test_module "Parser tests" = (module struct
  let check input =
    let result = from_string input in
    print_s [%sexp (result : (Value.t, Error.t) result)]

  let%expect_test "simple key-value" =
    check "key = \"value\"";
    [%expect {|
      (Ok (Table ((key (String value)))))
    |}]

  let%expect_test "integer" =
    check "num = 42";
    [%expect {|
      (Ok (Table ((num (Integer 42)))))
    |}]

  let%expect_test "boolean" =
    check "enabled = true";
    [%expect {|
      (Ok (Table ((enabled (Boolean true)))))
    |}]
end)

(* Less preferred: Repeated boilerplate in each test *)
let%expect_test "parse simple key-value" =
  let result = from_string "key = \"value\"" in
  print_s [%sexp (result : (Value.t, Error.t) result)];
  [%expect {|
    (Ok (Table ((key (String value)))))
  |}]

let%expect_test "parse integer" =
  let result = from_string "num = 42" in
  print_s [%sexp (result : (Value.t, Error.t) result)];
  [%expect {|
    (Ok (Table ((num (Integer 42)))))
  |}]
```

Benefits of test modules with check functions:

- Reduces boilerplate by extracting common test patterns
- Groups related tests together with clear organization
- Check functions document the test pattern explicitly
- Easy to add new tests with minimal code
- Can have multiple check functions for different test patterns
- Test modules can be nested for hierarchical organization

### General Testing Guidelines

- Use `%test_module` to organize related tests
- Create check-style helper functions to reduce boilerplate
- Use `%expect_test` with `print_s` for visibility into test failures
- Always derive `sexp` for types that will be tested
- Tests use `ppx_inline_test` and are embedded in library files
- Integration tests go in `*/test/` directories
- Easy to update expected output with `dune promote`

When to use other test forms:

- `%test_unit` - Only for tests with side effects or when output doesn't matter
- `%test` - Avoid in favor of `%expect_test` with `print_s`

### Updating Expect Test Output

When expect test output changes, use `dune promote` to accept the new output instead of manually editing the expected output in the source file:

```bash
dune runtest        # Run tests, see failures
dune promote        # Accept the new output
dune runtest        # Verify tests pass
```

This is faster and less error-prone than manually copying output into `[%expect]` blocks.

## Module Access Conventions

Libraries in this monorepo re-export their submodules through a main module. Access submodules using dot syntax through the library's main module:

```ocaml
(* Good: Access through main library module *)
module Syntax = Shrubbery.Syntax
module Token = Shrubbery.Token
module Fail = Utility.Fail

(* Bad: Direct access to internal module names *)
module Syntax = Shrubbery_syntax  (* Don't do this from other libraries *)
```

This pattern ensures proper dependency tracking and avoids issues with module aliases.

## Recent Work

Based on git history, recent changes involve:

- Variable scoping fixes using fresh variables
- Avoiding quadratic blowup with Acc.t
- Switching to single-arity functions
- Iterator improvements in functional library
